#' ---
#'
#' title: Tidy the Federalist Papers and predict authorship of the disputed Federalist No. 18
#' date: 2025-05-20
#'
#' ---

library(tidyverse)
library(tidytext)
library(rvest)

## Scrape the data from Project Gutenberg ----------------------

# read the raw HTML
page <- read_html('https://www.gutenberg.org/cache/epub/18/pg18-images.html')

# get all the chapters
paragraphs <- html_elements(page, '.chapter')

# get just the text from the element we want
text <- html_text2(paragraphs)

d <- tibble(text)

# get rid of the slightly different version of Federalist 70
d <- d |>
  filter(str_detect(text, 'slightly different version', negate = TRUE))

# create a column for the title and attributed author
d <- d |>
  mutate(author = text |>
           str_extract('HAMILTON AND MADISON|HAMILTON OR MADISON|HAMILTON|MADISON|JAY') |>
           str_to_title(),
         title = str_extract(text, 'No. [A-Z].*'))

## Tidy and tokenize the data ----------------

tidy_federalist <- d |>
  # remove the salutation
  mutate(text = str_replace_all(text,
                                pattern = 'To the People of the State of New York:',
                                replacement = '')) |>
  # tokenize to words
  unnest_tokens(input = 'text',
                output = 'word')


## Create bags of words with a 3-word vocabaulary -------

vocabulary <- c('upon', 'therefore', 'although')

# filter our dataset to just include those vocabulary
# words
df <- tidy_federalist |>
  filter(word %in% vocabulary) |>
  mutate(word = factor(word))

# create three bags of words, one per author
hamilton_bag <- table(df$word[df$author == 'Hamilton'])
madison_bag <- table(df$word[df$author == 'Madison'])
jay_bag <- table(df$word[df$author == 'Jay'])

hamilton_bag
madison_bag
jay_bag


# compute the likelihood that Federalist 50
# was generated by each of these bags of words
fed50_bag <- table(df$word[df$title == 'No. L.'])
fed50_bag

likelihood_hamilton <- dmultinom(fed50_bag,
                                 prob = hamilton_bag)

likelihood_madison <- dmultinom(fed50_bag,
                                 prob = madison_bag)

likelihood_jay <- dmultinom(fed50_bag,
                                 prob = jay_bag)

## Validation, Validation, Validation ----------

# if our model is a good model,
# then it should correctly predict authors
# when we know the truth

# here are a few we know were written by Jay
fed2_bag <- table(df$word[df$title == 'No. II.'])
fed3_bag <- table(df$word[df$title == 'No. III.'])
fed4_bag <- table(df$word[df$title == 'No. IV.'])

dmultinom(fed2_bag, prob = hamilton_bag)
dmultinom(fed2_bag, prob = jay_bag)
dmultinom(fed2_bag, prob = madison_bag)
