---
title: "Clustering"
description: |
  For when we don't really know what we're looking for in our data and just want the computer to tell us what it sees.
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Broadly speaking, we can divide the approaches for modeling text data into two camps: supervised learning and unsupervised learning. [Supervised learning](sentiment-analysis.html) approaches tend to be the most familiar to social scientists -- there is some outcome we'd like to predict, so we fit a function observable covariates to try and predict it. In the context of text as data, this means we have a set of labeled documents, and we fit a model to see how well we can predict the labels (e.g. predicting the authorship of the [Federalist Papers](federalist-papers.html)).

Unsupervised learning, by comparison, is less about prediction and more about discovery. You start with a set of *unlabeled* documents, and ask the computer to see if it can find a sensible way to organize them. 